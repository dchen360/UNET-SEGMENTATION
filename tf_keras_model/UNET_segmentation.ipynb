{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNET_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa4u7lHt_DYT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "## model ##\n",
        "from __future__ import print_function\n",
        "import os\n",
        "# keras\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint, History\n",
        "from keras import backend as K\n",
        "\n",
        "# skimage\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.exposure import rescale_intensity\n",
        "from skimage import io\n",
        "\n",
        "# matplotlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive to get data"
      ],
      "metadata": {
        "id": "jT-8Nt7yAT9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSidVZ8_AXdS",
        "outputId": "e25148da-a3e8-4796-8436-47c95a23f628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pre-processing"
      ],
      "metadata": {
        "id": "i1_brb6h_5yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Need a method here to load all image/data in\n",
        "# load image need to have:\n",
        "# img_train, mask_train, img_test\n",
        "    \n",
        "# metadata loc: ~/code/Segmentation/metadata.csv\n",
        "# image data under column: 'CT_image_path'; corresponding lung mask column: 'lung_mask_path'\n",
        "\n",
        "# switch tensorflow dimension orders\n",
        "K.set_image_data_format('channels_last')\n",
        "rows = 512\n",
        "cols = 512\n",
        "smooth = 1.\n",
        "\n",
        "# class dataProcess(object):\n",
        "#     ## Initialization ##\n",
        "#     def __init__(self, rows, cols):\n",
        "#         self.rows = rows\n",
        "#         self.cols = cols\n",
        "#         # self.data_path = data_path\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/UNET/Dataset/train'\n",
        "test_data_path = '/content/drive/MyDrive/UNET/Dataset/test'\n",
        "save_to_path = '/content/drive/MyDrive/UNET/Dataset/predicted'\n",
        "image_pre = 'CT_lung_Dataset_20-03-24_image_2'\n",
        "lung_mask_pre = 'CT_lung_Dataset_20-03-24_lung_mask_2'\n",
        "test_pre = 'CT_lung_Dataset_20-03-24_image_5' # can change to 6 or 7 if need more testing data"
      ],
      "metadata": {
        "id": "oHP9qgzS_M5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_data():\n",
        "    ## get metadata ##\n",
        "    # metadata_path = '/home/zitiantang/code/Segmentation/metadata.csv'\n",
        "    # metadata_df = pd.read_csv(metadata_path, index_col=0)\n",
        "    \n",
        "    ## Initialize list for images and corresponding masks\n",
        "    image_train = []\n",
        "    lung_mask_train = []\n",
        "\n",
        "    ## Directly get data from train folder ##\n",
        "    for i in range(1,6):\n",
        "      image_path = os.path.join(train_data_path, image_pre+str(i)+'.npy')\n",
        "      lung_mask_path = os.path.join(train_data_path, lung_mask_pre+str(i)+'.npy')\n",
        "      image_train.append(np.load(image_path))\n",
        "      lung_mask_train.append(np.load(lung_mask_path))\n",
        "\n",
        "    ## Loop through metadata ##\n",
        "    # for i in range(metadata_df.shape[0]):\n",
        "    #     curr_row = metadata_df.iloc[i]\n",
        "    #     image_path = curr_row['CT_image_path']\n",
        "    #     isTrain = curr_row['is_Train']\n",
        "    #     if '20-03-24' in image_path:\n",
        "    #         if isTrain:\n",
        "    #             # mod_im = np.load(image_path)\n",
        "    #             # mod_im = mod_im[:,:,None]\n",
        "    #             # image_train.append(mod_im)\n",
        "    #             image_train.append(np.load(image_path))\n",
        "    #             # mod_msk = np.load(curr_row['lung_mask_path'])\n",
        "    #             # mod_msk = mod_msk[:,:,None]\n",
        "    #             # lung_mask_train.append(mod_msk)\n",
        "    #             lung_mask_train.append(np.load(curr_row['lung_mask_path']))\n",
        "\n",
        "    ## Image modification ##\n",
        "    # image_train = image_train.astype('float32')\n",
        "    # image_train /= 255\n",
        "    # lung_mask_train = lung_mask_train.astype('float32')\n",
        "    # lung_mask_train /= 255\n",
        "\n",
        "    ## Return ##\n",
        "    # return tuple(image_train), tuple(lung_mask_train)\n",
        "    \n",
        "    ## Create big nd arrays ##\n",
        "    imgs = np.ndarray((len(image_train), rows, cols), dtype=np.uint8) #np.array instead of np.ndarray\n",
        "    lung_masks = np.ndarray((len(lung_mask_train), rows, cols), dtype=np.uint8)\n",
        "    for idx, img in enumerate(image_train):\n",
        "        imgs[idx, :, :] = img #imgs[idx] is the same as imgs[idx,:,:]\n",
        "    for idx, img in enumerate(lung_mask_train):\n",
        "        lung_masks[idx, :, :] = img\n",
        "    \n",
        "    np.save(os.path.join(train_data_path, 'imgs_train.npy'), imgs)\n",
        "    np.save(os.path.join(train_data_path, 'lung_mask_train.npy'), lung_masks)"
      ],
      "metadata": {
        "id": "yUW7M00W_QPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_train_data():\n",
        "    image_train = np.load(os.path.join(train_data_path, 'imgs_train.npy'))\n",
        "    lung_mask_train = np.load(os.path.join(train_data_path, 'lung_mask_train.npy'))\n",
        "    return image_train, lung_mask_train"
      ],
      "metadata": {
        "id": "SDGyYXjv_Vb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_data():\n",
        "    ## get metadata ##\n",
        "    # metadata_path = '/home/zitiantang/code/Segmentation/metadata.csv'\n",
        "    # metadata_df = pd.read_csv(metadata_path, index_col=0)\n",
        "\n",
        "    ## Initialize list for testing images ##\n",
        "    image_test = []\n",
        "\n",
        "    ## get testing data directly from folder ##\n",
        "    for i in range(1,3):\n",
        "      image_test_path = os.path.join(test_data_path, test_pre+str(i)+'.npy')\n",
        "      image_test.append(np.load(image_test_path))\n",
        "\n",
        "    ## Loop through metadata ##\n",
        "    # for i in range(metadata_df.shape[0]):\n",
        "    #     curr_row = metadata_df.iloc[i]\n",
        "    #     image_path = curr_row['CT_image_path']\n",
        "    #     isTrain = curr_row['is_Train']\n",
        "    #     if '20-03-24' in image_path:\n",
        "    #         if ~isTrain:\n",
        "    #             # mod_im = np.load(image_path)\n",
        "    #             # mod_im = mod_im[:,:,None]\n",
        "    #             # image_test.append(mod_im)\n",
        "    #             image_test.append(np.load(image_path))\n",
        "    \n",
        "    ## Image modification ##\n",
        "    # image_test = image_test.astype('float32')\n",
        "    # image_test /= 255\n",
        "\n",
        "    ## Return ##\n",
        "    # return tuple(image_test)\n",
        "\n",
        "    ## Create big nd array ##\n",
        "    imgtest = np.ndarray((len(image_test), rows, cols), dtype=np.uint8)\n",
        "    for idx, img in enumerate(image_test):\n",
        "        imgtest[idx, :, :] = img\n",
        "    np.save(os.path.join(test_data_path, 'imgs_test.npy'), imgtest)"
      ],
      "metadata": {
        "id": "JGm57K9c_XKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_data():\n",
        "    image_test = np.load(os.path.join(test_data_path, 'imgs_test.npy'))\n",
        "    return image_test"
      ],
      "metadata": {
        "id": "jNoTDY8I_bsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Only need to run once ##\n",
        "create_train_data()\n",
        "create_test_data()"
      ],
      "metadata": {
        "id": "Lh2z85miNdpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNET Model and Training"
      ],
      "metadata": {
        "id": "roZKHgCs_0eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Define dice lost ##\n",
        "def dice_coef(y_true, y_pred):\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  intersection = K.sum(y_true_f * y_pred_f)\n",
        "  return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "  return -dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "JUGNNCB7T8DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet():\n",
        "    inputs = Input((rows, cols, 1))\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=1e-3), loss=dice_coef_loss, metrics=[dice_coef])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "nY5JvzuM_4dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training"
      ],
      "metadata": {
        "id": "cmRrbFdOAKFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocessing input images ##\n",
        "def preprocess(imgs):\n",
        "    imgs_p = np.ndarray((imgs.shape[0], rows, cols), dtype=np.uint8)\n",
        "    for i in range(imgs.shape[0]):\n",
        "        imgs_p[i] = resize(imgs[i], (cols, rows), preserve_range=True)\n",
        "\n",
        "    imgs_p = imgs_p[..., np.newaxis]\n",
        "    return imgs_p"
      ],
      "metadata": {
        "id": "hsyWuOwBYpbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    print('-'*30)\n",
        "    print('Loading and preprocessing train data...')\n",
        "    print('-'*30)\n",
        "    imgs_train, imgs_mask_train = load_train_data()\n",
        "\n",
        "    imgs_train = preprocess(imgs_train)\n",
        "    imgs_mask_train = preprocess(imgs_mask_train)\n",
        "\n",
        "    imgs_train = imgs_train.astype('float32')\n",
        "    mean = np.mean(imgs_train)  # mean for data centering\n",
        "    std = np.std(imgs_train)  # std for data normalization\n",
        "\n",
        "    imgs_train -= mean\n",
        "    imgs_train /= std\n",
        "    #Normalization of the train set\n",
        "\n",
        "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
        "\n",
        "    print('-'*30)\n",
        "    print('Creating and compiling model...')\n",
        "    print('-'*30)\n",
        "    model = get_unet()\n",
        "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss')\n",
        "    #Saving the weights and the loss of the best predictions we obtained\n",
        "\n",
        "    print('-'*30)\n",
        "    print('Fitting model...')\n",
        "    print('-'*30)\n",
        "    history=model.fit(imgs_train, imgs_mask_train, batch_size=5, epochs=5, verbose=1, shuffle=True,\n",
        "              callbacks=[model_checkpoint])\n",
        "\n",
        "    print('-'*30)\n",
        "    print('Loading and preprocessing test data...')\n",
        "    print('-'*30)\n",
        "    imgs_test = load_test_data()\n",
        "    imgs_test = preprocess(imgs_test)\n",
        "\n",
        "    imgs_test = imgs_test.astype('float32')\n",
        "    imgs_test -= mean\n",
        "    imgs_test /= std\n",
        "    #Normalization of the test set\n",
        "\n",
        "    # print('-'*30)\n",
        "    # print('Loading saved weights...')\n",
        "    # print('-'*30)\n",
        "    # model.load_weights('weights.h5')\n",
        "\n",
        "    print('-'*30)\n",
        "    print('Predicting masks on test data...')\n",
        "    print('-'*30)\n",
        "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
        "    np.save(os.path.join(save_to_path, 'lung_mask_test.npy'), imgs_mask_test)\n",
        "    print('-' * 30)\n",
        "    print('Saving predicted masks to files...')\n",
        "    print('-' * 30)\n",
        "    # pred_dir = 'preds'\n",
        "    # if not os.path.exists(pred_dir):\n",
        "    #     os.mkdir(pred_dir)\n",
        "\n",
        "    for k in range(len(imgs_mask_test)):\n",
        "        a=rescale_intensity(imgs_test[k][:,:,0],out_range=(-1,1))\n",
        "        b=(imgs_mask_test[k][:,:,0]).astype('uint8')\n",
        "        io.imsave(os.path.join(save_to_path, str(k) + '_pred.png'),mark_boundaries(a,b))\n",
        "    #Saving our predictions in the directory 'preds'\n",
        "\n",
        "    plt.plot(history.history['dice_coef'])\n",
        "    # plt.plot(history.history['val_dice_coef'])\n",
        "    plt.title('Model dice coeff')\n",
        "    plt.ylabel('Dice coeff')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "    #plotting our dice coeff results in function of the number of epochs"
      ],
      "metadata": {
        "id": "O2s-IMgzZE2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "-bDUMSGfZSAu",
        "outputId": "8c3ce2dc-ea8c-4215-b5a9-e1280395e048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "Loading and preprocessing train data...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Creating and compiling model...\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "Fitting model...\n",
            "------------------------------\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 48s 48s/step - loss: -0.4206 - dice_coef: 0.4206\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 35s 35s/step - loss: -0.4297 - dice_coef: 0.4297\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 38s 38s/step - loss: -0.4364 - dice_coef: 0.4364\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 36s 36s/step - loss: -0.4539 - dice_coef: 0.4539\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 35s 35s/step - loss: -0.5164 - dice_coef: 0.5164\n",
            "------------------------------\n",
            "Loading and preprocessing test data...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Predicting masks on test data...\n",
            "------------------------------\n",
            "1/1 [==============================] - 4s 4s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "Saving predicted masks to files...\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}